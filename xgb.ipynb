{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost\n",
    "from xgboost import XGBRegressor, XGBModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboostextension import XGBRanker, XGBFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model.config import Config\n",
    "from model.data_utils import load_vocab, get_mean_NDCG\n",
    "from ast import literal_eval\n",
    "from scipy.spatial.distance import cosine, correlation, braycurtis, \\\n",
    "    euclidean, mahalanobis, minkowski, seuclidean, sqeuclidean, wminkowski \n",
    "from model.data_utils import get_trimmed_glove_vectors, get_mean_NDCG, ndcg_at_k, get_predictions\n",
    "from fastText import load_model\n",
    "import argparse\n",
    "import errno\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = 0.99\n",
    "label_to_num = {\"good\": 2, \"neutral\": 1, \"bad\": 1 - conf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.path_to_train)\n",
    "val = pd.read_csv(config.path_to_val)\n",
    "test = pd.read_csv(config.path_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_trimmed_glove_vectors(config.filename_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(indices, vocab):\n",
    "    # indices must be a list of int indices\n",
    "    try:\n",
    "        indices = literal_eval(indices)\n",
    "    except ValueError:\n",
    "        indices = indices\n",
    "    \n",
    "    embedded_sentence = np.take(vocab, indices, axis=0)\n",
    "    return embedded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(dataframe, vocab, f=euclidean):\n",
    "    total_distances = []\n",
    "    for _id in list(dataframe.context_id.unique()):\n",
    "        partition = dataframe.loc[dataframe['context_id'] == _id]\n",
    "        distances = []\n",
    "        context = literal_eval(partition.merged_contexts.iloc[0])\n",
    "        context_vector = get_embedding(context, vocab)\n",
    "        mean_context = np.mean(context_vector, axis=0)\n",
    "        replies = [literal_eval(x) for x in partition.reply]\n",
    "        for reply, reply_id in zip(replies, partition.reply_id):\n",
    "            reply_vector = get_embedding(reply, vocab)\n",
    "            mean_reply = np.mean(reply_vector, axis=0)\n",
    "            #distance = (mean_context - mean_reply) ** 2\n",
    "            distance = f(mean_context, mean_reply)\n",
    "            #distances = np.append(distances, distance)\n",
    "            distances.append(distance)\n",
    "        total_distances.extend(distances)\n",
    "    return total_distances   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointwise_distances(dataframe, vocab, f=euclidean):\n",
    "    total_distances = []\n",
    "    for _id in list(dataframe.context_id.unique()):\n",
    "        partition = dataframe.loc[dataframe['context_id'] == _id]\n",
    "        distances = []\n",
    "        context = literal_eval(partition.merged_contexts.iloc[0])\n",
    "        context_vector = get_embedding(context, vocab)\n",
    "        mean_context = np.mean(context_vector, axis=0)\n",
    "        replies = [literal_eval(x) for x in partition.reply]\n",
    "        for reply, reply_id in zip(replies, partition.reply_id):\n",
    "            reply_vector = get_embedding(reply, vocab)\n",
    "            mean_reply = np.mean(reply_vector, axis=0)\n",
    "            distance = (mean_context - mean_reply) ** 2\n",
    "            #distance = f(mean_context, mean_reply)\n",
    "            #distances = np.append(distances, distance)\n",
    "            distances.append(distance)\n",
    "        total_distances.extend(distances)\n",
    "    return total_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lens(dataframe):\n",
    "    lens = []\n",
    "    for _id in list(dataframe.context_id.unique()):\n",
    "        partition = dataframe.loc[dataframe['context_id'] == _id]\n",
    "        lens.append(len(partition))\n",
    "    return lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_xgb_predictions(dataframe, predictitons):\n",
    "    total_predictions = []\n",
    "    for _id in list(dataframe.context_id.unique()):\n",
    "        partition = dataframe.loc[dataframe['context_id'] == _id]\n",
    "        #print (partition.index)\n",
    "        #print (np.take(l, partition.index, axis=0))\n",
    "        partial_preds = np.take(predictitons, partition.index, axis=0)\n",
    "        p = list(enumerate(partial_preds))\n",
    "        #print (p)\n",
    "        p = sorted(p, key=lambda x: -x[-1])\n",
    "        predicted_indices = [x[0] for x in p]\n",
    "        #print (predicted_indices)\n",
    "        predicted_probas = [x[1] for x in p]\n",
    "        #print (predicted_probas)\n",
    "        total_predictions.extend(predicted_indices)\n",
    "    return total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(objective=\"rank:pairwise\")\n",
    "ranker = XGBRanker(n_estimators=150, learning_rate=0.1, subsample=0.9)#, objective='rank:pairwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array(get_pointwise_distances(val, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array([label_to_num[x] for x in val.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_val = compute_lens(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "     colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "     max_depth=3, min_child_weight=1, missing=None, n_estimators=150,\n",
       "     n_jobs=-1, nthread=None, objective='rank:pairwise', random_state=0,\n",
       "     reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "     subsample=0.9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X, y_train)\n",
    "ranker.fit(X_val, y_val, lens_val, eval_metric=['ndcg', 'map@5-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(get_pointwise_distances(test, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_test = compute_lens(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = ranker.predict(X_test, lens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21180984, 0.6886587 , 0.6181052 , ..., 0.07714647, 0.7477301 ,\n",
       "       0.65852785], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21180984, 0.6886587 , 0.6181052 , 0.49548346, 0.37640887,\n",
       "       0.10057464], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_y_preds = sort_xgb_predictions(test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82169.31546564518"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean_NDCG(test, sorted_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(get_pointwise_distances(train, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([label_to_num[x] for x in train.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_train = compute_lens(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "     colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "     max_depth=3, min_child_weight=1, missing=None, n_estimators=150,\n",
       "     n_jobs=-1, nthread=None, objective='rank:pairwise', random_state=0,\n",
       "     reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "     subsample=0.9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.fit(X_train, y_train, lens_train, eval_metric=['ndcg', 'map@5-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(get_pointwise_distances(test, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_test = compute_lens(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = ranker.predict(X_test, lens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28118122, 0.50867206, 0.5582693 , ..., 0.5609416 , 0.48988783,\n",
       "       0.5289386 ], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_y_preds = sort_xgb_predictions(test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 1, 4, 3, 0, 2, 0, 5, 3, 1, 4]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y_preds[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82118.08758614419"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean_NDCG(test, sorted_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same but with one number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(get_distances(train, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "     colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "     max_depth=3, min_child_weight=1, missing=None, n_estimators=150,\n",
       "     n_jobs=-1, nthread=None, objective='rank:pairwise', random_state=0,\n",
       "     reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "     subsample=0.9)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train = np.array(get_pointwise_distances(train, vocab))\n",
    "#y_train = np.array([label_to_num[x] for x in train.label])\n",
    "#lens_train = compute_lens(train)\n",
    "ranker.fit(X_train, y_train, lens_train, eval_metric=['ndcg', 'map@5-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(get_distances(test, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = ranker.predict(X_test, lens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.506596  , 0.50798625, 0.51695615, ..., 0.49014026, 0.49723178,\n",
       "       0.50464606], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_y_preds = sort_xgb_predictions(test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81913.16572027517"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean_NDCG(test, sorted_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial sumbmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.path_to_preprocessed_train)\n",
    "X = np.array(get_pointwise_distances(train, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([label_to_num[x] for x in train.label])\n",
    "lens_train = compute_lens(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = XGBRanker(n_estimators=500, learning_rate=0.1, subsample=0.9,\n",
    "                  max_depth=10)#, objective='rank:pairwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "     colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "     max_depth=10, min_child_weight=1, missing=None, n_estimators=500,\n",
       "     n_jobs=-1, nthread=None, objective='rank:pairwise', random_state=0,\n",
       "     reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "     subsample=0.9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.fit(X, y_train, lens_train, eval_metric=['ndcg', 'map@5-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train NDCG: 79385.90735486381\n"
     ]
    }
   ],
   "source": [
    "train_preds = ranker.predict(X)\n",
    "sorted_train_preds = sort_xgb_predictions(train, train_preds)\n",
    "train_ndcg = get_mean_NDCG(train, sorted_train_preds)\n",
    "print ('train NDCG:', train_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(ranker, open(\"../data/xgb_models/500_estimators.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(config.path_to_preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(get_pointwise_distances(test, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_test = compute_lens(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ranker.predict(X_test, lens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01572004, 0.8037063 , 0.4488865 , ..., 0.7053027 , 1.2431805 ,\n",
       "       0.3948659 ], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_y_preds = sort_xgb_predictions(test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 5, 2, 4, 0, 1, 0, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y_preds[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sub = \"../data/ranking_xgb_500_depth_10_baseline.txt\"\n",
    "with open(path_to_sub,\"w+\") as f:\n",
    "    for k, v in (zip(test.context_id.values, sorted_y_preds)):\n",
    "        f.write(\"%s %s\" % (k, v))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
