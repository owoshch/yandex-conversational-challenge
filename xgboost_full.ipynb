{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboostextension import XGBRanker, XGBFeature\n",
    "from model.config import Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model.data_utils import get_trimmed_glove_vectors, \\\n",
    "    get_embedding, get_distances, get_pointwise_distances, \\\n",
    "    compute_lengths, sort_xgb_predictions, get_mean_NDCG\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(path_to_submission, dataframe, predictions):\n",
    "    with open(path_to_sub,\"w+\") as f:\n",
    "        for k, v in (zip(dataframe.context_id.values, predictions)):\n",
    "            f.write(\"%s %s\" % (k, v))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = 0.9\n",
    "label_to_num = {\"good\": 2, \"neutral\": 1, \"bad\": 1 - conf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.path_to_train)\n",
    "val = pd.read_csv(config.path_to_val)\n",
    "test = pd.read_csv(config.path_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_trimmed_glove_vectors(config.filename_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = XGBRanker(n_estimators=150, learning_rate=0.1, subsample=0.9)#, objective='rank:pairwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(get_pointwise_distances(train, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([label_to_num[x] for x in train.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_train = compute_lengths(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.fit(X_train, y_train, lengths_train, eval_metric=['ndcg', 'map@5-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = ranker.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_train_preds = sort_xgb_predictions(train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ndcg = get_mean_NDCG(train, sorted_train_preds)\n",
    "print ('train NDCG:', train_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array(get_pointwise_distances(val, vocab))\n",
    "lengths_val = compute_lengths(val)\n",
    "val_preds = ranker.predict(X_val, lengths_val)\n",
    "sorted_val_preds = sort_xgb_predictions(val, val_preds)\n",
    "val_ndcg = get_mean_NDCG(val, sorted_val_preds)\n",
    "print ('val NDCG:', val_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_val = compute_lengths(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = ranker.predict(X_val, lengths_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_val_preds = sort_xgb_predictions(val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ndcg = get_mean_NDCG(val, sorted_val_preds)\n",
    "print ('val NDCG:', val_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(get_pointwise_distances(test, vocab))\n",
    "print ('Test dataframe was preprocessed')\n",
    "lengths_test = compute_lengths(test)\n",
    "test_preds = ranker.predict(X_test, lengths_test)\n",
    "print ('Test predictions were computed')\n",
    "sorted_test_preds = sort_xgb_predictions(test, test_preds)\n",
    "test_ndcg = get_mean_NDCG(test, sorted_test_preds)\n",
    "print ('Test NDCG:', test_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_xgb_model = \"saved_ranker.pickle.dat\"\n",
    "pickle.dump(ranker, open(path_to_xgb_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(path_to_xgb_model, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_ranker(train, test, val, vocab, config, n_estimators=150, max_depth=3, learning_rate=0.1, \\\n",
    "                    subsample=0.9, conf=0.9):\n",
    "    # train, test and val are the dataframes\n",
    "    # vocab is a dictionary\n",
    "    label_to_num = {\"good\": 2, \"neutral\": 1, \"bad\": 1 - conf}\n",
    "    print ('label to num', label_to_num)\n",
    "    ranker = XGBRanker(n_estimators=n_estimators, learning_rate=learning_rate, \\\n",
    "                       subsample=subsample, max_depth=max_depth)\n",
    "    X_train = np.array(get_pointwise_distances(train, vocab))\n",
    "    print ('Train was preprocessed')\n",
    "    lengths_train = compute_lengths(train)\n",
    "    y_train = np.array([label_to_num[x] for x in train.label])\n",
    "    print ('Start training')\n",
    "    ranker.fit(X_train, y_train, lengths_train, eval_metric=['ndcg', 'map@5-'])\n",
    "    train_preds = ranker.predict(X_train, lengths_train)\n",
    "    sorted_train_preds = sort_xgb_predictions(train, train_preds)\n",
    "    train_ndcg = get_mean_NDCG(train, sorted_train_preds)\n",
    "    print ('Train NDCG:', train_ndcg)\n",
    "    \n",
    "    print ('Start validation')\n",
    "    X_val = np.array(get_pointwise_distances(val, vocab))\n",
    "    lengths_val = compute_lengths(val)\n",
    "    val_preds = ranker.predict(X_val, lengths_val)\n",
    "    sorted_val_preds = sort_xgb_predictions(val, val_preds)\n",
    "    val_ndcg = get_mean_NDCG(val, sorted_val_preds)\n",
    "    print ('val NDCG:', val_ndcg)\n",
    "\n",
    "    print ('Start test')\n",
    "    X_test = np.array(get_pointwise_distances(test, vocab))\n",
    "    print ('Test dataframe was preprocessed')\n",
    "    lengths_test = compute_lengths(test)\n",
    "    test_preds = ranker.predict(X_test, lengths_test)\n",
    "    print ('Test predictions were computed')\n",
    "    sorted_test_preds = sort_xgb_predictions(test, test_preds)\n",
    "    test_ndcg = get_mean_NDCG(test, sorted_test_preds)\n",
    "    print ('Test NDCG:', test_ndcg)\n",
    "    \n",
    "    path_to_xgb_model = config.path_to_xgb_models + \"xgb_n_estimators_%s_depth_%s_lr_%s_subsample_%s_conf_%s_val_%s_test_%s.pickle.dat\" % \\\n",
    "    (n_estimators, max_depth, learning_rate, subsample, conf, val_ndcg, test_ndcg)\n",
    "    \n",
    "    print ('Saving model')\n",
    "    pickle.dump(ranker, open(path_to_xgb_model, \"wb\"))\n",
    "    \n",
    "    return train_ndcg, val_ndcg, test_ndcg, path_to_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loaded\n",
      "label to num {'neutral': 1, 'bad': 0.010000000000000009, 'good': 2}\n",
      "Train was preprocessed\n",
      "Start training\n",
      "Train NDCG: 83141.777727717\n",
      "Start validation\n",
      "val NDCG: 82656.29002118148\n",
      "Start test\n",
      "Test dataframe was preprocessed\n",
      "Test predictions were computed\n",
      "Test NDCG: 82118.08758614419\n",
      "Saving model\n",
      "label to num {'neutral': 1, 'bad': 0.010000000000000009, 'good': 2}\n",
      "Train was preprocessed\n",
      "Start training\n",
      "Train NDCG: 83058.52869175769\n",
      "Start validation\n",
      "val NDCG: 83229.33478587391\n",
      "Start test\n",
      "Test dataframe was preprocessed\n",
      "Test predictions were computed\n",
      "Test NDCG: 82300.57094307899\n",
      "Saving model\n",
      "label to num {'neutral': 1, 'bad': 0.010000000000000009, 'good': 2}\n",
      "Train was preprocessed\n",
      "Start training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e9693518d3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_ndcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ndcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ndcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_xgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_xgb_ranker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m                                                                              \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_xgb_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlog_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlog_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train NDCG:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ndcg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8b953fa56464>\u001b[0m in \u001b[0;36mtrain_xgb_ranker\u001b[0;34m(train, test, val, vocab, config, n_estimators, max_depth, learning_rate, subsample, conf)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Start training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mranker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ndcg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'map@5-'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msorted_train_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_xgb_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/XGBoost_Ranking-0.7.0-py3.5.egg/xgboostextension/xgbranker.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, group, eval_metric, sample_weight, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    100\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                               xgb_model=None)\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 895\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "train = pd.read_csv(config.path_to_train)\n",
    "val = pd.read_csv(config.path_to_val)\n",
    "test = pd.read_csv(config.path_to_test)\n",
    "vocab = get_trimmed_glove_vectors(config.filename_trimmed)\n",
    "print ('Data is loaded')\n",
    "n_estimators = 150\n",
    "max_depth = 3\n",
    "learning_rate = 0.1\n",
    "subsample = 0.9\n",
    "conf = 0.9\n",
    "val_ndcg = 82118.08758614419\n",
    "test_ndcg = 83248.08758614419\n",
    "if not os.path.exists(config.path_to_xgb_models):\n",
    "    os.makedirs(config.path_to_xgb_models)\n",
    "for conf in [0.99, 0.5]:\n",
    "    for max_depth in [3, 5, 10]:\n",
    "        train_ndcg, val_ndcg, test_ndcg, path_to_xgb_model = train_xgb_ranker(train, test, val, vocab, config, \\\n",
    "                                                                             conf=conf, max_depth=max_depth)\n",
    "        with open(config.path_to_xgb_log, 'a+') as log_file:\n",
    "            log_file.write('train NDCG:' + str(train_ndcg) + '\\n')\n",
    "            log_file.write('val NDCG: ' + str(val_ndcg) + '\\n')\n",
    "            log_file.write('test NDCG: ' + str(test_ndcg) + '\\n')\n",
    "            log_file.write('_______________________\\n')\n",
    "            log_file.write('n estimators: ' + str(n_estimators) + '\\n')\n",
    "            log_file.write('max depth: ' + str(max_depth) + '\\n')\n",
    "            log_file.write('learning rate: ' + str(learning_rate) + '\\n')\n",
    "            log_file.write('subsample: ' + str(subsample) + '\\n')\n",
    "            log_file.write('conf: ' + str(conf) + '\\n')\n",
    "            #path_to_xgb_model = \"xgb_n_estimators_%s_depth_%s_lr_%s_subsample_%s_conf_%s_val_%s_test_%s.pickle.dat\" % (n_estimators, max_depth, learning_rate, subsample, conf, val_ndcg, test_ndcg)\n",
    "            log_file.write('path to model: ' + path_to_xgb_model + ' \\n')\n",
    "            log_file.write('=======================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
